{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a02a7dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np,pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.linalg import block_diag\n",
    "from sklearn.utils import check_random_state\n",
    "from typing import TypeVar\n",
    "PandasDataFrame = TypeVar('pandas.core.frame.DataFrame')\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = '1'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d9e05079",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From previous chapter \n",
    "def cov2corr(cov):\n",
    "    std = np.sqrt(np.diag(cov))\n",
    "    corr = cov/np.outer(std,std)\n",
    "    corr[corr<-1], corr[corr>1] = -1, 1 \n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f4f687a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimal_Clustering:\n",
    "    \"\"\"\n",
    "    Updated K-means algorithm by:\n",
    "    1) Introducing objective function as silhouette score and qualify clusters by it\n",
    "    2) Dealing with initialization problem by having a first loop (which attemps different initialisations) \n",
    "        for anothers loops which check different amount of clusters and check quality in them\n",
    "        -----------------------\n",
    "        (New improvement of base algorithm:)\n",
    "        \n",
    "    3) Deals with clusters of inconsistent quality. The base clustering may capture the more distinct clusters, \n",
    "        while missing theless apparent ones\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod \n",
    "    def clusterKMeansBase(corr0: PandasDataFrame, maxNumClusters: int = 10, \n",
    "                          n_init: int = 10) -> Tuple[PandasDataFrame, int, pd.Series]:\n",
    "        \"\"\"\n",
    "        Base algorithm for next improved version of clustering. Consisint of first two imporvement of K-means\n",
    "\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        :param corr0: correlation between of observations \n",
    "\n",
    "        :param maxNumClusters: - amount of clusters from 2 to maxNumClusters+1 that will be checked\n",
    "            and evaluate quality for each amount of clusters\n",
    "\n",
    "        :param n_init: number of different initialisation 0,1,..,init \n",
    "            to be checked to evaluate quality for each initialisation for each amount of clusters\n",
    "\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        corr1 - pd.DataFrame\n",
    "            reduced correlation sorted by best quality observations \n",
    "\n",
    "        clstrs - set\n",
    "            best clustering of observations\n",
    "\n",
    "        silh -  pd.Series\n",
    "            silhouette coefficient for each set of clusters\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        x = ((1 - corr0.fillna(0))/2.)**.5  #calculating the distance matrix            \n",
    "        silh = pd.Series(dtype = 'float64')\n",
    "\n",
    "\n",
    "        for init in range(n_init):\n",
    "            for i in range(2, maxNumClusters + 1):\n",
    "\n",
    "\n",
    "                kmeans_ = KMeans(n_clusters = i, n_init = 1)\n",
    "                kmeans_ = kmeans_.fit(x)\n",
    "\n",
    "\n",
    "                silh_ = silhouette_samples(x, kmeans_.labels_) #calculate Silhouette Coefficient for each sample\n",
    "                stat = (silh_.mean()/silh_.std(), silh.mean()/silh.std()) #calculating clustering quality\n",
    "\n",
    "                #if quality is better then previous one - remember new model and Silhouette Coefficient\n",
    "                if np.isnan(stat[1]) or stat[0]>stat[1]: \n",
    "                    silh, kmeans = silh_, kmeans_\n",
    "\n",
    "        #creating new distance matrix and sorting by quality\n",
    "        newIdx = np.argsort(kmeans.labels_) \n",
    "        corr1 = corr0.iloc[newIdx] \n",
    "        corr1 = corr1.iloc[:,newIdx]\n",
    "\n",
    "        #getting all clusters with different quality\n",
    "        clstrs = {i:corr0.columns[np.where(kmeans.labels_ == i)[0]].tolist() for i in np.unique(kmeans.labels_) }  \n",
    "\n",
    "        silh = pd.Series(silh, index = x.index, dtype = 'float64')\n",
    "\n",
    "        return corr1, clstrs, silh\n",
    "\n",
    "\n",
    "    def makeNewOutputs(self, corr0: PandasDataFrame, \n",
    "                       clstrs: set, clstrs2: set) -> Tuple[PandasDataFrame, int, pd.Series]:\n",
    "        \"\"\"\n",
    "        function for combining  two different clusters with their quaility and correlation matrix\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        :param corr0: correlation between of observations \n",
    "        :param clstrs: first cluster of observation \n",
    "        :param  clstrs2: second cluster of observation\n",
    "\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        corrNew - pd.DataFrame\n",
    "            united correlation of two clusters of observations \n",
    "\n",
    "        clstrsNew - set\n",
    "            united list of clusters of observations\n",
    "\n",
    "        silhNew -  pd.Series\n",
    "            united silhouette coefficient for each set of clusters\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        clstrsNew = {}\n",
    "\n",
    "        #getting unioun of lists of clusters\n",
    "        for i in clstrs.keys():\n",
    "            clstrsNew[len(clstrsNew.keys())] = list(clstrs[i])\n",
    "\n",
    "        for i in clstrs2.keys():\n",
    "            clstrsNew[len(clstrsNew.keys())] = list(clstrs2[i])\n",
    "\n",
    "        #creating united correlation matrix    \n",
    "        newIdx = [j for i in clstrsNew for j in clstrsNew[i]]\n",
    "        corrNew = corr0.loc[newIdx, newIdx]\n",
    "        x = ((1 - corr0.fillna(0))/2.)**.5 #creating new distance matrix\n",
    "        kmeans_labels = np.zeros(len(x.columns))\n",
    "\n",
    "        for i in clstrsNew.keys():\n",
    "            idxs = [x.index.get_loc(k) for k in clstrsNew[i]]\n",
    "            kmeans_labels[idxs] = i\n",
    "\n",
    "        #checking Silhouette Coefficient for new united cluster\n",
    "        silhNew = pd.Series(silhouette_samples(x,kmeans_labels), index = x.index, dtype = 'float64')\n",
    "\n",
    "        return corrNew, clstrsNew, silhNew\n",
    "    \n",
    "    def clusterKMeansTop(self, corr0: PandasDataFrame,\n",
    "                         maxNumClusters: int = None, n_init: int = 10) -> Tuple[PandasDataFrame, int, pd.Series]:\n",
    "        \"\"\"\n",
    "        Main function of class that uses all 3 improvement of K-means clustering\n",
    "\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        :param corr0: correlation between of observations \n",
    "\n",
    "        :param maxNumClusters: - amount of clusters that will be checked\n",
    "            and evaluate quality for each amount of clusters\n",
    "\n",
    "        :param n_init: number of different initialisation 0,1,..,init \n",
    "            to be checked to evaluate quality for each initialisation for each amount of clusters\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        corr1 - pd.DataFrame\n",
    "            reduced correlation sorted by best quality observations \n",
    "\n",
    "        clstrs - list\n",
    "            best clustering of observations\n",
    "\n",
    "        silh -  pd.Series\n",
    "            silhouette coefficient for each set of clusters\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        #define maximum of clusters if got none\n",
    "        if maxNumClusters == None: maxNumClusters = corr0.shape[1] - 1\n",
    "\n",
    "\n",
    "        #evaluating base fucntion for clasterisation \n",
    "        corr1, clstrs, silh = self.clusterKMeansBase(corr0, maxNumClusters = \n",
    "                                                min(maxNumClusters, corr0.shape[1] - 1), n_init = n_init)\n",
    "\n",
    "        #evaluate the quality of each cluster\n",
    "        clusterTstats = {i: np.mean(silh[clstrs[i]])/ (np.std(silh[clstrs[i]])+0.001) for i in clstrs.keys()}\n",
    "\n",
    "\n",
    "        #finding set of clusters with quality below average\n",
    "        tStatMean = sum(clusterTstats.values())/len(clusterTstats)\n",
    "        redoClusters=[i for i in clusterTstats.keys() if clusterTstats[i] < tStatMean]\n",
    "\n",
    "\n",
    "        #if returned 1 or less clusters then the base algorithm was optimal\n",
    "        if len(redoClusters) <= 1:\n",
    "            return corr1, clstrs, silh\n",
    "\n",
    "\n",
    "        #if number of clusters with quality below average is more than one \n",
    "        # we need to rerun clustering in those clusters, while rest considered well clustered\n",
    "        else:\n",
    "            keysRedo = [j for i in redoClusters for j in clstrs[i]]\n",
    "            corrTmp = corr0.loc[keysRedo, keysRedo] #creating new corr maxtrix for reduced observations\n",
    "                                                    #(those with clusters quality below average)\n",
    "\n",
    "\n",
    "            #Checking mean quality for clusters with quality below average\n",
    "            tStatMean = np.mean([clusterTstats[i] for i in redoClusters])\n",
    "            corr2, clstrs2, silh2 = self.clusterKMeansTop(corrTmp, \n",
    "                                                     maxNumClusters = min(maxNumClusters, corrTmp.shape[1] - 1), \n",
    "                                                     n_init = n_init)\n",
    "\n",
    "\n",
    "        #joining optimal clusters that were above average and new ones\n",
    "        corrNew, clstrsNew, silhNew = self.makeNewOutputs(corr0, \n",
    "                                                     {i: clstrs[i] for i in clstrs.keys() if i not in redoClusters}, \n",
    "                                                     clstrs2)\n",
    "\n",
    "        #Checking new mean quality\n",
    "        newTstatMean = np.mean([np.mean(silhNew[clstrsNew[i]]) / (np.std(silhNew[clstrsNew[i]])+0.001) for i in clstrsNew.keys()])\n",
    "\n",
    "\n",
    "        #comparing for improvement of algorithm and giving more optimal result\n",
    "        if newTstatMean <= tStatMean:\n",
    "            return corr1, clstrs, silh\n",
    "        else:\n",
    "            return corrNew, clstrsNew, silhNew\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9b2d4eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Random_Block_Correlation_Matrices:\n",
    "    \"\"\"\n",
    "    Generation of Random Block Correlation Matrices. Monte Carlo\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    :param nObs: number of observation \n",
    "    \n",
    "    :param nCols: number of columns\n",
    "    \n",
    "    :param sigma: Standard deviation of the distribution\n",
    "    \n",
    "    :param random_state: fix the random by entering seed\n",
    "    \n",
    "    :paramn Blocks:\n",
    "    \n",
    "    :param minBlockSize:   \n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod \n",
    "    def getCovSub(nObs: int, nCols: int, sigma: Tuple[float, int] , random_state: int = None) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generating random covariance matrix by number of observations and columns\n",
    "        \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        \n",
    "        ar0 - np.ndarray\n",
    "            random covariance matrix where each column represents a variable, \n",
    "            while the rows contain observations.\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        rng = check_random_state(random_state)\n",
    "        \n",
    "        if nCols == 1:\n",
    "            return np.ones((1,1))\n",
    "\n",
    "        ar0 = rng.normal(size = (nObs,1))\n",
    "        ar0 = np.repeat(ar0, nCols, axis = 1)\n",
    "        ar0 += rng.normal(scale = sigma, size = ar0.shape)\n",
    "        ar0 = np.cov(ar0, rowvar = False)\n",
    "        \n",
    "        \n",
    "        return ar0\n",
    "\n",
    "\n",
    "    def getRndBlockCov(self, nCols: int, nBlocks: int, minBlockSize: int = 1, \n",
    "                       sigma: Tuple[float, int] = 1., random_state: int = None) -> np.ndarray:\n",
    "        \n",
    "        \"\"\"\n",
    "        Generating random diagonal of covariance matrix\n",
    "        \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        ar0 - np.ndarray\n",
    "            random covariance matrix with zeros\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        rng = check_random_state(random_state)\n",
    "        \n",
    "        #random sample from a given array\n",
    "        parts = rng.choice(range(1, nCols - (minBlockSize - 1)*nBlocks),\n",
    "                           nBlocks - 1, replace = False)\n",
    "        \n",
    "        \n",
    "        parts.sort()\n",
    "        parts = np.append(parts, nCols - (minBlockSize-1)*nBlocks)\n",
    "        parts = np.append(parts[0], np.diff(parts)) - 1 + minBlockSize\n",
    "        cov = None\n",
    "        \n",
    "        \n",
    "        for nCols_ in parts:\n",
    "            #generate covariance matrix\n",
    "            nObs = int(max(nCols_*(nCols_ + 1)/2., 100))\n",
    "            cov_= self.getCovSub(nObs, nCols_, sigma, random_state = rng)\n",
    "            \n",
    "            \n",
    "            if cov is None:\n",
    "                cov = cov_.copy()\n",
    "            else:\n",
    "                cov = block_diag(cov, cov_)\n",
    "                \n",
    "        return cov\n",
    "    \n",
    "    def randomBlockCorr(self, nCols: int, nBlocks: int, random_state: int = None, minBlockSize: int = 1) -> pd.DataFrame():\n",
    "        \"\"\"\n",
    "        Generating random block of corellation matrix\n",
    "        \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        ar0 - np.ndarray\n",
    "            random covariance matrix with zeros\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        rng = check_random_state(random_state)\n",
    "        cov0 = self.getRndBlockCov(nCols, nBlocks, minBlockSize = minBlockSize, sigma = .5, random_state = rng)\n",
    "        cov1 = self.getRndBlockCov(nCols, 1 ,minBlockSize = minBlockSize, sigma= 1., random_state = rng)\n",
    "        cov0 += cov1\n",
    "        corr0 = cov2corr(cov0)\n",
    "        corr0 = pd.DataFrame(corr0)\n",
    "        \n",
    "        return corr0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecc6045",
   "metadata": {},
   "source": [
    "### Checking of random generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f73b0817",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd = Random_Block_Correlation_Matrices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "669bdfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cor = rnd.randomBlockCorr(10,10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e503f018",
   "metadata": {},
   "outputs": [],
   "source": [
    "oc = Optimal_Clustering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "84cda05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrNew, clstrsNew, silhNew = oc.clusterKMeansTop(cor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "60e8fbdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.287130</td>\n",
       "      <td>0.302079</td>\n",
       "      <td>0.267462</td>\n",
       "      <td>0.290355</td>\n",
       "      <td>0.287395</td>\n",
       "      <td>0.281367</td>\n",
       "      <td>0.299143</td>\n",
       "      <td>0.287887</td>\n",
       "      <td>0.375113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.287130</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.378757</td>\n",
       "      <td>0.309739</td>\n",
       "      <td>0.314949</td>\n",
       "      <td>0.250392</td>\n",
       "      <td>0.264539</td>\n",
       "      <td>0.293714</td>\n",
       "      <td>0.259873</td>\n",
       "      <td>0.262234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.302079</td>\n",
       "      <td>0.378757</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.412650</td>\n",
       "      <td>0.314393</td>\n",
       "      <td>0.377985</td>\n",
       "      <td>0.383591</td>\n",
       "      <td>0.305856</td>\n",
       "      <td>0.341106</td>\n",
       "      <td>0.325173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.267462</td>\n",
       "      <td>0.309739</td>\n",
       "      <td>0.412650</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.317591</td>\n",
       "      <td>0.194235</td>\n",
       "      <td>0.297797</td>\n",
       "      <td>0.191816</td>\n",
       "      <td>0.315236</td>\n",
       "      <td>0.229094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.290355</td>\n",
       "      <td>0.314949</td>\n",
       "      <td>0.314393</td>\n",
       "      <td>0.317591</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.274655</td>\n",
       "      <td>0.205417</td>\n",
       "      <td>0.231482</td>\n",
       "      <td>0.227272</td>\n",
       "      <td>0.234002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.287395</td>\n",
       "      <td>0.250392</td>\n",
       "      <td>0.377985</td>\n",
       "      <td>0.194235</td>\n",
       "      <td>0.274655</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.323916</td>\n",
       "      <td>0.278926</td>\n",
       "      <td>0.232884</td>\n",
       "      <td>0.280203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.281367</td>\n",
       "      <td>0.264539</td>\n",
       "      <td>0.383591</td>\n",
       "      <td>0.297797</td>\n",
       "      <td>0.205417</td>\n",
       "      <td>0.323916</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.290930</td>\n",
       "      <td>0.268295</td>\n",
       "      <td>0.306712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.299143</td>\n",
       "      <td>0.293714</td>\n",
       "      <td>0.305856</td>\n",
       "      <td>0.191816</td>\n",
       "      <td>0.231482</td>\n",
       "      <td>0.278926</td>\n",
       "      <td>0.290930</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.284218</td>\n",
       "      <td>0.292368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.287887</td>\n",
       "      <td>0.259873</td>\n",
       "      <td>0.341106</td>\n",
       "      <td>0.315236</td>\n",
       "      <td>0.227272</td>\n",
       "      <td>0.232884</td>\n",
       "      <td>0.268295</td>\n",
       "      <td>0.284218</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.272804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.375113</td>\n",
       "      <td>0.262234</td>\n",
       "      <td>0.325173</td>\n",
       "      <td>0.229094</td>\n",
       "      <td>0.234002</td>\n",
       "      <td>0.280203</td>\n",
       "      <td>0.306712</td>\n",
       "      <td>0.292368</td>\n",
       "      <td>0.272804</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  1.000000  0.287130  0.302079  0.267462  0.290355  0.287395  0.281367   \n",
       "1  0.287130  1.000000  0.378757  0.309739  0.314949  0.250392  0.264539   \n",
       "2  0.302079  0.378757  1.000000  0.412650  0.314393  0.377985  0.383591   \n",
       "3  0.267462  0.309739  0.412650  1.000000  0.317591  0.194235  0.297797   \n",
       "4  0.290355  0.314949  0.314393  0.317591  1.000000  0.274655  0.205417   \n",
       "5  0.287395  0.250392  0.377985  0.194235  0.274655  1.000000  0.323916   \n",
       "6  0.281367  0.264539  0.383591  0.297797  0.205417  0.323916  1.000000   \n",
       "7  0.299143  0.293714  0.305856  0.191816  0.231482  0.278926  0.290930   \n",
       "8  0.287887  0.259873  0.341106  0.315236  0.227272  0.232884  0.268295   \n",
       "9  0.375113  0.262234  0.325173  0.229094  0.234002  0.280203  0.306712   \n",
       "\n",
       "          7         8         9  \n",
       "0  0.299143  0.287887  0.375113  \n",
       "1  0.293714  0.259873  0.262234  \n",
       "2  0.305856  0.341106  0.325173  \n",
       "3  0.191816  0.315236  0.229094  \n",
       "4  0.231482  0.227272  0.234002  \n",
       "5  0.278926  0.232884  0.280203  \n",
       "6  0.290930  0.268295  0.306712  \n",
       "7  1.000000  0.284218  0.292368  \n",
       "8  0.284218  1.000000  0.272804  \n",
       "9  0.292368  0.272804  1.000000  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5a1724dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [2, 3, 6, 8], 1: [0, 5, 7, 9], 2: [1, 4]}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clstrsNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "01792940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.024660\n",
       "1    0.009376\n",
       "2    0.025474\n",
       "3    0.018410\n",
       "4    0.036012\n",
       "5    0.001010\n",
       "6    0.009750\n",
       "7    0.017933\n",
       "8    0.024749\n",
       "9    0.026864\n",
       "dtype: float64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silhNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20045259",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
