{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64fa48ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np,scipy.stats as ss\n",
    "from sklearn.metrics import mutual_info_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a795211f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceMetrics:\n",
    "    \"\"\"\n",
    "    Metrics that help to quantify the amount of information contained in data\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    :param X: observations of x random variable\n",
    "    :param Y: observations of y random variable\n",
    "    :bins: using histogram-based estimation for estimation distance metrics\n",
    "    \n",
    "    :nObs: number of observation\n",
    "    :corr: correlation between observable random variables\n",
    "    :normalised: give output of normalized data\n",
    "    \"\"\"\n",
    "        \n",
    "#--------------------------------------------------------------------------     \n",
    "\n",
    "    @staticmethod \n",
    "    def numBins(nObs: int , corr: int = None) -> int:\n",
    "        \n",
    "        \"\"\"\n",
    "        Function for finding optimal amount of bins for \n",
    "        dataset of discretized continious random variables\n",
    "        \"\"\"\n",
    "        \n",
    "        if corr is None: \n",
    "            z = (8 + 324*nObs + 12*(36*nObs + 729*nObs**2)**.5)**(1/3.)\n",
    "            b = round(z/6. + 2./(3*z) + 1./3)\n",
    "            \n",
    "        else: \n",
    "            b = round(2**(-.5) * (1 + (1 + 24*nObs/(1. - corr**2))**.5)**.5)\n",
    "            \n",
    "        return int(b)\n",
    "    \n",
    "#--------------------------------------------------------------------------  \n",
    "\n",
    "    @staticmethod \n",
    "    def entropy(X: np.ndarray, bins: int) -> float:\n",
    "        \n",
    "        \"\"\"\n",
    "        Function for finding entropy, i.e the amount of uncertainty associated with X.\n",
    "        \"\"\"\n",
    "        \n",
    "        hX = ss.entropy(np.histogram(X, bins)[0]) \n",
    "        \n",
    "        return hX\n",
    "    \n",
    "#--------------------------------------------------------------------------        \n",
    "\n",
    "    def mutual_info(self, X: np.ndarray, Y: np.ndarray, bins: int, normalised: bool = False) -> float:\n",
    "        \n",
    "        \"\"\"\n",
    "        Functions for finding mutual information of X,Y , i.e the decrease in uncertainty (or informational\n",
    "        gain) in X that results from knowing the value of Y.\n",
    "        \"\"\"\n",
    "        \n",
    "    \n",
    "        cXY = np.histogram2d(X, Y, bins)[0]\n",
    "        iXY = mutual_info_score(None, None, contingency = cXY)\n",
    "\n",
    "        if normalised:\n",
    "            hX = self.entropy(X, bins) \n",
    "            hY = self.entropy(Y, bins) \n",
    "            iXY = iXY / min(hX, hY)\n",
    "        \n",
    "        return iXY\n",
    "    \n",
    "#--------------------------------------------------------------------------        \n",
    "    \n",
    "    def join_entropy(self, X: np.ndarray, Y: np.ndarray, bins: int)  -> float:\n",
    "        \"\"\"\n",
    "        Function for finding the joint entropy of X and Y, i.e.\n",
    "        the measure of the uncertainty associated with a set of X and Y\n",
    "        \"\"\"\n",
    "        \n",
    "        hX = self.entropy(X, bins)\n",
    "        hY = self.entropy(X, bins)\n",
    "\n",
    "        iXY = self.mutual_info(X, Y, bins)\n",
    "\n",
    "        hXY = hX + hY - iXY #join entropy by formula\n",
    "\n",
    "        return hXY\n",
    "\n",
    "#--------------------------------------------------------------------------    \n",
    "\n",
    "    def conditional_entropy(self, X: np.ndarray, Y: np.ndarray, bins: int)  -> float:\n",
    "        \n",
    "        \"\"\"\n",
    "        Functions for condtional entropy of X if Y is known ,\n",
    "        i.e the amount of information needed to describe the outcome of a \n",
    "        random variable Y given that the value of another random variable X is known.\n",
    "        \"\"\"\n",
    "                \n",
    "        hXY = self.join_entropy(X, Y, bins)\n",
    "        hY = self.entropy(Y, bins)\n",
    "        hX_Y = hXY - hY #conditional entropy by formula\n",
    "    \n",
    "        return hX_Y\n",
    "    \n",
    "#--------------------------------------------------------------------------    \n",
    "\n",
    "    def varInfo(self, X: np.ndarray, Y: np.ndarray, bins: int, normalised: bool = False) -> float:\n",
    "        \n",
    "        \"\"\"\n",
    "        Functions for finding variarion  of information of X,Y , i.e the uncertainty \n",
    "        we expect in one variable if we are told the value of other\n",
    "        \"\"\"\n",
    "        \n",
    "        iXY = self.mutual_info(X, Y, bins)\n",
    "        hX = self.entropy(X, bins) \n",
    "        hY = self.entropy(Y, bins) \n",
    "\n",
    "        vXY = hX + hY - 2*iXY #Variation of information by formula\n",
    "        \n",
    "        if normalised:\n",
    "            hXY = hX + hY - iXY \n",
    "            vXY = vXY/hXY \n",
    "            \n",
    "        return vXY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98912ed",
   "metadata": {},
   "source": [
    "# Checking working of fuctions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f3c7b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "size,seed=5000,0\n",
    "np.random.seed(seed)\n",
    "x=np.random.normal(size=size)\n",
    "e=np.random.normal(size=size)\n",
    "y=0*x+e\n",
    "corr=np.corrcoef(x,y)[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d705cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = DistanceMetrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29664489",
   "metadata": {},
   "source": [
    "### numbins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5487b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = metric.numBins(x.shape[0], corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4da97e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_bins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4688a32",
   "metadata": {},
   "source": [
    "### entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7144047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9638844237154696"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.entropy(x, n_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f123f2c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.119199896008615"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.entropy(y, n_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682c3a90",
   "metadata": {},
   "source": [
    "### mutual_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaea53be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006764619108279091"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.mutual_info(x,y, n_bins, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da24552a",
   "metadata": {},
   "source": [
    "### join_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c8eeaca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9144839173318218"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.join_entropy(x,y, n_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afdb2f7",
   "metadata": {},
   "source": [
    "### condtional_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa954d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7952840213232069"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.conditional_entropy(x,y, n_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8834d424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.261230438202643"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.conditional_entropy(y,x, n_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548f01aa",
   "metadata": {},
   "source": [
    "### varInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df483368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9967357285145346"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.varInfo(x,y, n_bins, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
